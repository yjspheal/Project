{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72fd420d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 코드\n",
    "\n",
    "import time\n",
    "import re\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import openpyxl as xl\n",
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_youtube_data(brand, goods):\n",
    "    search_goods = f'{brand} {goods}'\n",
    "    \n",
    "    # 드라이버 주소 설정\n",
    "    browser = webdriver.Chrome(\".\\chromedriver.exe\") \n",
    "    browser.implicitly_wait(1)   \n",
    "    \n",
    "    # 크롤링 데이터를 저장할 경로 및 엑셀 파일 이름 지정\n",
    "    try:      # 데이터 100개를 저장할 폴더 생성('YT_data') 및 이미 존재하는 폴더일 시 예외처리\n",
    "        os.mkdir(\"YT_data\") \n",
    "    except FileExistsError:\n",
    "        print('YT_data 폴더가 이미 존재합니다. 해당 폴더에 데이터를 저장합니다.')\n",
    "    result = pd.ExcelWriter(\"./YT_data/\" + search_goods + '.xlsx', engine='openpyxl')\n",
    "    \n",
    "    # 유튜브 검색을 위한 url을 만들어 열고 body 추출\n",
    "    yt_url = \"https://www.youtube.com\"\n",
    "    search_goods = search_goods.replace(' ','+')  # url용으로 제품명 사이 공백 +로 대체\n",
    "    target_url  = yt_url + \"/results?search_query=\"+search_goods + \"+리뷰\" + \"&sp=CAI%253D\"      # 업로드날짜 필터링\n",
    "    browser.get(target_url)\n",
    "    body = browser.find_element_by_tag_name('body')\n",
    "    \n",
    "    # 전체 데이터를 추출하기 위하여 페에지를 쭉 내림. 필터링이 되기 때문에 50번이면 충분\n",
    "    for pg_down in range(50):  # 페이지 다운 수\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        browser.implicitly_wait(1)\n",
    "    \n",
    "    # 해당 페이지 html 소스를 beautifulsoup을 이용하여 html 에 저장\n",
    "    html0 = browser.page_source\n",
    "    html = BeautifulSoup(html0,'html.parser')\n",
    "    \n",
    "    # 검색 결과창에서 각 비디오 하나씩을 나누어줌\n",
    "    video_datas = html.find_all('ytd-video-renderer',{'class':'style-scope ytd-item-section-renderer'})\n",
    "\n",
    "    \n",
    "    #데이터 저장을 위한 기본 데이터프레임 생성\n",
    "    dataframe = pd.DataFrame({'title':[], 'youtube_url':[], 'subscribers':[], 'views':[], \"nice\":[], \"reply\":[]})\n",
    "    \n",
    "    # 비디오 url을 저장할 리스트 생성(해당 url은 youtube.com/ 이후에 들어가는 부분)\n",
    "    video_url_list = []\n",
    "    for i in range(len(video_datas)):\n",
    "        # 검색 결과 창에서 얻을 수 있는 데이터인 동영상 제목(title)과 동영상 링크 추출\n",
    "        title = video_datas[i].find('a',{'id':'video-title'}).get_text() \n",
    "        url = yt_url + video_datas[i].find('a',{'id':'thumbnail'})['href'] \n",
    "        video_url_list.append(url)\n",
    "        \n",
    "        # 상세 동영상 페이지 접속 및 바디 추출\n",
    "        cur_url = video_url_list[i]\n",
    "        browser.get(cur_url); time.sleep(5)\n",
    "        body = browser.find_element_by_tag_name('body')\n",
    "        \n",
    "        # 댓글 수를 보려면 페이지를 동영상 목록까지 내린 후 기다려야 나오므로 페이지를 내리고 기다리는 과정을 반복\n",
    "        for pg_down in range(10):\n",
    "            body.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.5)\n",
    "        \n",
    "        # 현재 동영상 페이지 소스코드를 beautifulsoup 이용하여 html에 저장\n",
    "        html0 = browser.page_source\n",
    "        html = BeautifulSoup(html0,'html.parser')\n",
    "        \n",
    "        # 조회수, 좋아요수, 댓글수는 영상마다 감춰두거나 막아놓는 경우가 있어 에러가 발생하여 예외처리\n",
    "        try:\n",
    "            \n",
    "            # 조회수를 크롤링하고, nnn,nnn회 라는 결과를 얻게 되어 replace로 정리하여 정수로 저장\n",
    "            view_count = html.find('span',{'class':'view-count style-scope ytd-video-view-count-renderer'}).get_text().split()[1]\n",
    "            view_count = view_count.replace(\",\", \"\"); view_count = view_count.replace(\"회\", \"\"); view_count = int(view_count)\n",
    "            \n",
    "            # 채널명(유튜버)를 크롤링하여 youtuber에 저장\n",
    "            channel = html.find(\"div\", {'class' : 'style-scope ytd-channel-name'})     # 채널명을 나타내는 태그와 class는 여러 곳에서 쓰이므로, class style-scope ytd-channel-name를 이용하여 chammel에 저장 후 chammel에서 해당 형태를 다시 찾아냄\n",
    "            youtuber = channel.find(\"a\", {\"class\" : 'yt-simple-endpoint style-scope yt-formatted-string'}).get_text()\n",
    "            \n",
    "            # 데이터 정제를 위하여 조회수가 500 미만이거나 채널 명에 브랜드가 포함되는 경우(즉 브랜드 자체 광고 동영상인 경우) 해당 동영상은 넘기고 다음 '동영상'으로 넘어감\n",
    "            if view_count < 500 or youtuber.find(brand) != -1:\n",
    "                continue       \n",
    "            \n",
    "            # 업로드 일자를 크롤링하여 만약 현재(코드를 돌리는 시점)부터 6개월 이전에 만들어진 영상이라면 break하고 다음 '제품'으로 넘어감(업로드 일자를 기준으로 정렬된 동영상들이기 때문에 이 이후는 볼 필요가 없으므로 break)\n",
    "            upload_date = html.find_all(\"yt-formatted-string\", {\"class\" : \"style-scope ytd-video-primary-info-renderer\"})[1].get_text()\n",
    "            daybefore = dt.datetime.today() - dt.timedelta(days = 180) \n",
    "            upload_date = upload_date[:len(upload_date)-1]\n",
    "            ul_year, ul_month, ul_day = map(int,upload_date.split(\".\"))\n",
    "            if daybefore > dt.datetime(ul_year, ul_month, ul_day):   # 업로드 6개월 이전이라면 break\n",
    "                break\n",
    "            \n",
    "            # 좋아요 수 크롤링, 좋아요 수는 싫어요 수와 같은 태그 및 class를 가지고 그중 첫번째에 해당함\n",
    "            nice = html.find_all(\"yt-formatted-string\",{\"class\" : \"style-scope ytd-toggle-button-renderer style-text\"})[0]\n",
    "            # get_text를 하면 'n.n만개'처럼 축약된 형태가 반환되고, 태그 속 aria-label에 상세한 좋아요 수가 들어있어 이를 반환\n",
    "            nice_count = nice[\"aria-label\"].split()[-1]     # '좋아요 nnnnn개'의 형태가 반환되므로 split함\n",
    "        \n",
    "            # 좋아요 수가 100개 이하인 경우 콤마가 포함되지 않는 숫자가 반환되어 replace가 에러날 수 있으므로 문자로 변환하였다가 정제 후 정수로 다시 변환하여 저장\n",
    "            nice_count = str(nice_count)\n",
    "            nice_count = nice_count.replace(\",\", \"\"); nice_count = nice_count.replace(\"개\", \"\")\n",
    "            nice_count = int(nice_count)\n",
    "            \n",
    "            # 구독자 수를 아래의 태그와 id를 이용하여 크롤링\n",
    "            subscribers = html.find(\"yt-formatted-string\",{\"id\" : \"owner-sub-count\"}).get_text().split()[1]\n",
    "            \n",
    "            # 댓글 수 크롤링. 댓글 수를 나타내는 태그와 class는 아래의 답글 수 등에서도 계속 사용되기 때문에 info에 댓글 수가 있는 comments-header를 추출하여 저장 후 사용\n",
    "            info = html.find('h2', {'class' : 'style-scope ytd-comments-header-renderer'})\n",
    "            reply_count = info.find_all('span', {'class' : 'style-scope yt-formatted-string'})[1].get_text()    #info에는 댓글/nnn/개 의 소스가 저장되어있어 2번째 인자 추출하여 get_text\n",
    "            reply_count = int(reply_count)    # nnn의 형태이나 문자이므로 정수로 변환하여 저장\n",
    "            \n",
    "            # 각 데이터를 합쳐 데이터프레임을 만들고 insert_data에 저장\n",
    "            insert_data = pd.DataFrame({'title':[title], 'youtube_url':[url], 'subscribers':[subscribers], 'views':[view_count], \"nice\":[nice_count], \"reply\":[reply_count]})\n",
    "            print(\"추출 Yes\\n\")  # 코드 실행 중 가시화를 위한 코드\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue \n",
    "         \n",
    "        # insert_data를 위에 만들었던 dataframe에 합쳐넣고, 이를 엑셀로 변환하여 저장\n",
    "        dataframe = dataframe.append(insert_data)\n",
    "        dataframe.to_excel(result, index = False)\n",
    "        result.save()\n",
    "    \n",
    "    # dataframe에 들어가는 데이터가 없는 경우, 즉 최근 6개월 이내에 올라온 조회수 500 이상의 리뷰 동영상이 없는 경우 엑셀이 제대로 저장되지 않으므로 데이터프레임을 하나 만들어서 저장\n",
    "    if dataframe.shape[0] == 0:\n",
    "        dataframe = pd.DataFrame({'title': [], 'youtube_url': [], 'subscribers':[], 'views':[0], \"nice\":[0], \"reply\":[0]})   # 조회수가 0인 영상을 존재하지 않기 때문에 시각화 과정에서 이를 이용하여 실제 데이터와 분리\n",
    "        dataframe.to_excel(result, index = False)\n",
    "        result.save()\n",
    "    \n",
    "\n",
    "def youtube_crawling():\n",
    "    # 제품 명과 브랜드 이름이 들어있는 엑셀 파일을 불러와 활성화\n",
    "    raw_data = xl.load_workbook('올리브영랭크100위화장품정보.xlsx')\n",
    "    raw_data = raw_data.active\n",
    "    \n",
    "    # C, D열에서 각각 제품 명과 브랜드 이름(이 들어있는 셀 리스트)를 slice하여 저장\n",
    "    goods_name = raw_data[\"C\"][1::]\n",
    "    brand_name = raw_data[\"D\"][1::]\n",
    "\n",
    "    # get_youtube_data 함수에 제품명과 브랜드를 넣어 실행\n",
    "    for i in range(100):\n",
    "        print(f'rank {i+1}',end = ' ')  # 코드 실행 중 가시화를 위한 코드\n",
    "        goods = goods_name[i].value   # _name[i] 자체는 셀이기 때문에 value로 셀의 내용을 추출하여 저장\n",
    "        brand = brand_name[i].value\n",
    "        get_youtube_data(brand, goods)\n",
    "        \n",
    "        \n",
    "# 기존 엑셀에 유튜브 데이터 추가하는 함수\n",
    "def excel_add_youtube():\n",
    "    # 기존 정보 들어있는 엑셀을 load하고 활성화시킴\n",
    "    raw_datad = xl.load_workbook('올리브영랭크100위화장품정보.xlsx')\n",
    "    raw_data = raw_datad.active\n",
    "    \n",
    "    # 저장된 100개의 파일 불러오기 위한 브랜드, 제품명 가져오기\n",
    "    goods_name = raw_data[\"C\"][1::]; brand_name = raw_data[\"D\"][1::]\n",
    "    \n",
    "    # format을 맞추기 위해 첫번째 행에 들어갈 값들 지정\n",
    "    raw_data[\"Q1\"] = \"유튜브 컨텐츠 수\"; raw_data[\"R1\"] = \"총 조회수\"; raw_data[\"S1\"] = \"총 좋아요수\"; raw_data[\"T1\"] = \"총 댓글수\"\n",
    "    \n",
    "    # 100개의 파일을 불러와 기존 엑셀에 대하여 유튜브 컨텐츠 수, 총 조회수, 좋아요수, 댓글수 추출하여 저장\n",
    "    for i in range(100):\n",
    "        goods = goods_name[i].value\n",
    "        brand = brand_name[i].value\n",
    "\n",
    "        filed = xl.load_workbook('./YT_data/'+f'{brand} {goods}'+\".xlsx\")  # 파일 이름으로 불러오므로 폴더 내에 데이터 순서에 무관하게 각 파일을 가져옴\n",
    "        file = filed.active\n",
    "        \n",
    "        # 각 파일 내에서 조회수, 좋아요수, 댓글 수 들어있는 열을 가져옴\n",
    "        views = file[\"D\"][1::]; nices = file[\"E\"][1::]; replies = file[\"F\"][1::] \n",
    "        \n",
    "        # 컨텐츠의 갯수는 파일의 행 갯수로 가져옴\n",
    "        contents_count = len(file[\"E\"][1::])\n",
    "        \n",
    "        # 각 셀의 value를 가져와 총 합계를 각각 구함\n",
    "        views_sum = 0; nices_sum = 0; replies_sum = 0\n",
    "        for v in views:\n",
    "            views_sum += v.value\n",
    "        \n",
    "        for n in nices:\n",
    "            nices_sum += n.value\n",
    "        \n",
    "        for r in replies:\n",
    "            replies_sum += r.value\n",
    "\n",
    "    # 구한 값들을 차례로 엑셀 칸에 집어넣음\n",
    "    raw_data[f\"Q{i+2}\"] = contents_count; raw_data[f\"R{i+2}\"] = views_sum; raw_data[f\"S{i+2}\"] = nices_sum; raw_data[f\"T{i+2}\"] = replies_sum\n",
    "    \n",
    "    # 만든 엑셀 데이터를 새로운 이름으로 저장\n",
    "    raw_datad.save('올리브영랭크100위화장품정보+유튜브데이터.xlsx')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7dca842d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\uj200\\anaconda3\\lib\\site-packages\\openpyxl\\worksheet\\_reader.py:312: UserWarning: Conditional Formatting extension is not supported and will be removed\n",
      "  warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rank 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uj200\\AppData\\Local\\Temp/ipykernel_34028/2593710359.py:20: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome(\".\\chromedriver.exe\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YT_data 폴더가 이미 존재합니다. 해당 폴더에 데이터를 저장합니다.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uj200\\AppData\\Local\\Temp/ipykernel_34028/2593710359.py:35: DeprecationWarning: find_element_by_tag_name is deprecated. Please use find_element(by=By.TAG_NAME, value=name) instead\n",
      "  body = browser.find_element_by_tag_name('body')\n",
      "C:\\Users\\uj200\\AppData\\Local\\Temp/ipykernel_34028/2593710359.py:64: DeprecationWarning: find_element_by_tag_name is deprecated. Please use find_element(by=By.TAG_NAME, value=name) instead\n",
      "  body = browser.find_element_by_tag_name('body')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102960 Yoo True / 추출 Yes\n",
      "\n"
     ]
    },
    {
     "ename": "WebDriverException",
     "evalue": "Message: chrome not reachable\n  (Session info: chrome=99.0.4844.84)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00AF9943+2595139]\n\tOrdinal0 [0x00A8C9F1+2148849]\n\tOrdinal0 [0x009843F0+1065968]\n\tOrdinal0 [0x009787C2+1017794]\n\tOrdinal0 [0x00978FF8+1019896]\n\tOrdinal0 [0x0097A892+1026194]\n\tOrdinal0 [0x00974219+999961]\n\tOrdinal0 [0x00985860+1071200]\n\tOrdinal0 [0x009DB2D2+1422034]\n\tOrdinal0 [0x009CB806+1357830]\n\tOrdinal0 [0x009A6086+1204358]\n\tOrdinal0 [0x009A6F96+1208214]\n\tGetHandleVerifier [0x00C9B232+1658114]\n\tGetHandleVerifier [0x00D5312C+2411516]\n\tGetHandleVerifier [0x00B8F261+560433]\n\tGetHandleVerifier [0x00B8E366+556598]\n\tOrdinal0 [0x00A9286B+2173035]\n\tOrdinal0 [0x00A975F8+2192888]\n\tOrdinal0 [0x00A976E5+2193125]\n\tOrdinal0 [0x00AA11FC+2232828]\n\tBaseThreadInitThunk [0x768CFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77527A7E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77527A4E+238]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mWebDriverException\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34028/3115651795.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0myoutube_crawling\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34028/2593710359.py\u001b[0m in \u001b[0;36myoutube_crawling\u001b[1;34m()\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mgoods\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgoods_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m   \u001b[1;31m# _name[i] 자체는 셀이기 때문에 value로 셀의 내용을 추출하여 저장\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m         \u001b[0mbrand\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbrand_name\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mget_youtube_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbrand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgoods\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_34028/2593710359.py\u001b[0m in \u001b[0;36mget_youtube_data\u001b[1;34m(brand, goods)\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[1;31m# 댓글 수를 보려면 페이지를 동영상 목록까지 내린 후 기다려야 나오므로 페이지를 내리고 기다리는 과정을 반복\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mpg_down\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mbody\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPAGE_DOWN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\uj200\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36msend_keys\u001b[1;34m(self, *value)\u001b[0m\n\u001b[0;32m    538\u001b[0m                 \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremote_files\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 540\u001b[1;33m         self._execute(Command.SEND_KEYS_TO_ELEMENT,\n\u001b[0m\u001b[0;32m    541\u001b[0m                       {'text': \"\".join(keys_to_typing(value)),\n\u001b[0;32m    542\u001b[0m                        'value': keys_to_typing(value)})\n",
      "\u001b[1;32mD:\\Users\\uj200\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webelement.py\u001b[0m in \u001b[0;36m_execute\u001b[1;34m(self, command, params)\u001b[0m\n\u001b[0;32m    708\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m         \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_id\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_parent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    711\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\uj200\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    423\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 425\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    427\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32mD:\\Users\\uj200\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_KT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0m_VT\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mWebDriverException\u001b[0m: Message: chrome not reachable\n  (Session info: chrome=99.0.4844.84)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00AF9943+2595139]\n\tOrdinal0 [0x00A8C9F1+2148849]\n\tOrdinal0 [0x009843F0+1065968]\n\tOrdinal0 [0x009787C2+1017794]\n\tOrdinal0 [0x00978FF8+1019896]\n\tOrdinal0 [0x0097A892+1026194]\n\tOrdinal0 [0x00974219+999961]\n\tOrdinal0 [0x00985860+1071200]\n\tOrdinal0 [0x009DB2D2+1422034]\n\tOrdinal0 [0x009CB806+1357830]\n\tOrdinal0 [0x009A6086+1204358]\n\tOrdinal0 [0x009A6F96+1208214]\n\tGetHandleVerifier [0x00C9B232+1658114]\n\tGetHandleVerifier [0x00D5312C+2411516]\n\tGetHandleVerifier [0x00B8F261+560433]\n\tGetHandleVerifier [0x00B8E366+556598]\n\tOrdinal0 [0x00A9286B+2173035]\n\tOrdinal0 [0x00A975F8+2192888]\n\tOrdinal0 [0x00A976E5+2193125]\n\tOrdinal0 [0x00AA11FC+2232828]\n\tBaseThreadInitThunk [0x768CFA29+25]\n\tRtlGetAppContainerNamedObjectPath [0x77527A7E+286]\n\tRtlGetAppContainerNamedObjectPath [0x77527A4E+238]\n"
     ]
    }
   ],
   "source": [
    "youtube_crawling()  #하다가 꺼서 에러난 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f038a54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632143e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d2558e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b1c87c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c70d13e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d1fb2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89f79b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975a846a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d97283",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a5b5da6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최종 main 코드(최종 코드에 포함되어있음)\n",
    "\n",
    "raw_data = xl.load_workbook('올리브영랭크100위화장품정보.xlsx')\n",
    "raw_data = raw_data.active\n",
    "\n",
    "goods_name = raw_data[\"C\"][1::]\n",
    "brand_name = raw_data[\"D\"][1::]\n",
    "\n",
    "for i in range(100):\n",
    "    goods = goods_name[i].value\n",
    "    brand = brand_name[i].value\n",
    "    crawling_youtube(brand, goods)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76e7317a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a684f2e9",
   "metadata": {},
   "source": [
    "# \n",
    "# \n",
    "# \n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d366c6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차(1차 + 구독자수 등)데이터 전처리 X, 값 없는 경우에 값 \"\"으로 채운 경우\n",
    "\n",
    "import time\n",
    "import re\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import openpyxl as xl\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from tqdm import tqdm\n",
    "\n",
    "def crawling_youtube(brand, goods):\n",
    "    search_goods = f'{brand} {goods}'\n",
    "    \n",
    "    # 드라이버 주소 설정\n",
    "    browser = webdriver.Chrome(\"C:\\Program Files\\Google\\Chrome\\Application\\chromedriver_win32\\\\chromedriver.exe\") \n",
    "    browser.implicitly_wait(1)   \n",
    "    \n",
    "    result = pd.ExcelWriter(\"./YT_data/\" + search_goods + '.xlsx', engine='openpyxl')\n",
    "    \n",
    "    yt_url = \"https://www.youtube.com\"\n",
    "    search_goods = search_goods.replace(' ','+')  # url용으로 제품명 사이 공백 +로 대체\n",
    "    target_url  = yt_url + \"/results?search_query=\"+search_goods + \"+리뷰\" + \"&sp=CAI%253D\"      # 업로드날짜 필터링\n",
    "    browser.get(target_url)\n",
    "    \n",
    "    body = browser.find_element_by_tag_name('body')\n",
    "\n",
    "    for pg_down in range(50):  # 페이지 다운 수\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        browser.implicitly_wait(1)\n",
    "\n",
    "    html0 = browser.page_source\n",
    "    html = BeautifulSoup(html0,'html.parser')\n",
    "\n",
    "    video_datas = html.find_all('ytd-video-renderer',{'class':'style-scope ytd-item-section-renderer'})\n",
    "    \n",
    "    dataframe = pd.DataFrame({'title':[], 'youtube_url':[], 'subscribers':[], 'views':[], \"nice\":[], \"reply\":[]})\n",
    "    video_url_list = []\n",
    "    \n",
    "    \n",
    "    for i in range(len(video_datas)):\n",
    "        url = yt_url + video_datas[i].find('a',{'id':'thumbnail'})['href']\n",
    "        video_url_list.append(url)\n",
    "\n",
    "        title = video_datas[i].find('a',{'id':'video-title'}).get_text()    \n",
    "        url = yt_url + video_datas[i].find('a',{'id':'thumbnail'})['href']\n",
    "    \n",
    "        cur_url = video_url_list[i]\n",
    "        browser.get(cur_url) \n",
    "        time.sleep(5)\n",
    "\n",
    "        body = browser.find_element_by_tag_name('body')\n",
    "        \n",
    "        for pg_down in range(10):\n",
    "            body.send_keys(Keys.PAGE_DOWN)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        html0 = browser.page_source\n",
    "        html = BeautifulSoup(html0,'html.parser')\n",
    "\n",
    "            \n",
    "        try:\n",
    "            view_count = html.find('span',{'class':'view-count style-scope ytd-video-view-count-renderer'}).get_text().split()[1]\n",
    "            view_count = view_count.replace(\",\", \"\"); view_count = view_count.replace(\"회\", \"\")\n",
    "            view_count = int(view_count)\n",
    "            \n",
    "            channel = html.find(\"div\", {'class' : 'style-scope ytd-channel-name'})\n",
    "            youtuber = channel.find(\"a\", {\"class\" : 'yt-simple-endpoint style-scope yt-formatted-string'}).get_text()\n",
    "            \n",
    "            print(view_count, youtuber, end = \" / \")\n",
    "            \n",
    "            if view_count < 500 or youtuber.find(brand) != -1: #조회수 500 미만, 브랜드 포함하는 경우 필터링\n",
    "                continue        \n",
    "            \n",
    "            upload_date = html.find_all(\"yt-formatted-string\", {\"class\" : \"style-scope ytd-video-primary-info-renderer\"})[1].get_text()\n",
    "            daybefore = dt.datetime.today() - dt.timedelta(days = 180)\n",
    "            upload_date = upload_date[:len(upload_date)-1]\n",
    "            ul_year, ul_month, ul_day = map(int,upload_date.split(\".\"))\n",
    "            \n",
    "            if daybefore > dt.datetime(ul_year, ul_month, ul_day):   # 업로드 6개월 이내\n",
    "                break\n",
    "            nice = html.find_all(\"yt-formatted-string\",{\"class\" : \"style-scope ytd-toggle-button-renderer style-text\"})[0]\n",
    "            nice_count = nice[\"aria-label\"].split()[-1]  #정확한 좋아요 수 반환\n",
    "            \n",
    "    \n",
    "            subscribers = html.find(\"yt-formatted-string\",{\"id\" : \"owner-sub-count\"}).get_text().split()[1]\n",
    "            \n",
    "            info = html.find('h2', {'class' : 'style-scope ytd-comments-header-renderer'})\n",
    "            reply_count = info.find_all('span', {'class' : 'style-scope yt-formatted-string'})[1].get_text()\n",
    "            reply_count = int(reply_count)\n",
    "            \n",
    "            insert_data = pd.DataFrame({'title':[title], 'youtube_url':[url], 'subscribers':[subscribers], 'views':[view_count], \"nice\":[nice_count], \"reply\":[reply_count]})\n",
    "            print(\"추출 O\\n\")\n",
    "        except Exception as e:\n",
    "            continue \n",
    "                        \n",
    "        dataframe = dataframe.append(insert_data)\n",
    "        dataframe.to_excel(result, index = False)\n",
    "        result.save()\n",
    "        \n",
    "    if dataframe.shape[0] == 0:\n",
    "        dataframe = pd.DataFrame({'title': [], 'youtube_url': [], 'subscribers':[], 'views':[], \"nice\":[], \"reply\":[]})\n",
    "        dataframe.to_excel(result, index = False)\n",
    "        result.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9abb97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce3496f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3677d66d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1b49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#데이터 후처리 시 위의 for 문에 집어넣은 코드\n",
    "\n",
    "raw_data = xl.load_workbook('올리브영랭크100위화장품정보.xlsx')\n",
    "raw_data = raw_data.active\n",
    "\n",
    "goods_name = raw_data[\"C\"][1::]\n",
    "brand_name = raw_data[\"D\"][1::]\n",
    "\n",
    "for i in range(100):\n",
    "    goods = goods_name[i].value\n",
    "    brand = brand_name[i].value\n",
    "\n",
    "    filed = xl.load_workbook('./YT_data/'+f'{brand} {goods}'+\".xlsx\")\n",
    "    file = filed.active\n",
    "    \n",
    "    nices = file[\"E\"][1::]\n",
    "    replies = file[\"F\"][1::]\n",
    "    \n",
    "    if len(nices) == 0:\n",
    "        file[\"D2\"] = 0; file[\"E2\"] = 0; file[\"F2\"] = 0\n",
    "        \n",
    "    for i in range(len(nices)):\n",
    "        nice = nices[i].value\n",
    "        nice = str(nice)\n",
    "        nice = nice.replace(\",\", \"\"); nice = nice.replace(\"개\", \"\")\n",
    "        nice = int(nice)\n",
    "        file[f\"E{i+2}\"] = nice\n",
    "        \n",
    "        reply = int(replies[i].value)\n",
    "        file[f\"F{i+2}\"] = reply\n",
    "        \n",
    "    filed.save('./YT_data/'+f'{brand} {goods}'+\".xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64abf7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b0705e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf699989",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34db900c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e4e2d89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "886e3f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엑셀에 붙이기\n",
    "\n",
    "raw_datad = xl.load_workbook('올리브영랭크100위화장품정보.xlsx')\n",
    "raw_data = raw_datad.active\n",
    "\n",
    "goods_name = raw_data[\"C\"][1::]\n",
    "brand_name = raw_data[\"D\"][1::]\n",
    "\n",
    "raw_data[\"Q1\"] = \"유튜브 컨텐츠 수\"\n",
    "raw_data[\"R1\"] = \"총 조회수\"\n",
    "raw_data[\"S1\"] = \"총 좋아요수\"\n",
    "raw_data[\"T1\"] = \"총 댓글수\"\n",
    "\n",
    "\n",
    "for i in range(100):\n",
    "    goods = goods_name[i].value\n",
    "    brand = brand_name[i].value\n",
    "\n",
    "    filed = xl.load_workbook('./YT_data/'+f'{brand} {goods}'+\".xlsx\")\n",
    "    file = filed.active\n",
    "    \n",
    "    views = file[\"D\"][1::]\n",
    "    nices = file[\"E\"][1::]\n",
    "    replies = file[\"F\"][1::]\n",
    "    \n",
    "    contents_count = len(file[\"E\"][1::])\n",
    "        \n",
    "    views_sum = 0\n",
    "    for v in views:\n",
    "        views_sum += v.value\n",
    "        \n",
    "    nices_sum = 0\n",
    "    for n in nices:\n",
    "        nices_sum += n.value\n",
    "        \n",
    "    replies_sum = 0\n",
    "    for r in replies:\n",
    "        replies_sum += r.value\n",
    "\n",
    "    raw_data[f\"Q{i+2}\"] = contents_count\n",
    "    raw_data[f\"R{i+2}\"] = views_sum\n",
    "    raw_data[f\"S{i+2}\"] = nices_sum\n",
    "    raw_data[f\"T{i+2}\"] = replies_sum\n",
    "    \n",
    "    raw_datad.save('올리브영랭크100위화장품정보.xlsx')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad0bb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292f63ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4608fdeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f11c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a020a563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1차, URL/ 타이틀 / 조회수 / 댓글수 /좋아요수 긁은 것\n",
    "import time\n",
    "import pandas as pd\n",
    "import openpyxl as xl\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from tqdm import tqdm\n",
    "\n",
    "def crawling_youtube(search_goods):\n",
    "    # 드라이버 주소 설정\n",
    "    browser = webdriver.Chrome(\"C:\\Program Files\\Google\\Chrome\\Application\\chromedriver_win32\\\\chromedriver.exe\") \n",
    "    browser.implicitly_wait(1)   \n",
    "    \n",
    "    result = pd.ExcelWriter(\"./YT_data/\" + search_goods + '.xlsx', engine='openpyxl')\n",
    "    \n",
    "    yt_url = \"https://www.youtube.com\"\n",
    "    search_goods = search_goods.replace(' ','+')  # url용으로 제품명 사이 공백 +로 대체\n",
    "    target_url  = yt_url + \"/results?search_query=\"+search_goods + \"+리뷰\" + \"&sp=CAM%253D\"      # 조회수 필터링\n",
    "    browser.get(target_url)\n",
    "    \n",
    "\n",
    "    body = browser.find_element_by_tag_name('body')\n",
    "\n",
    "    for pg_down in range(50):  # 페이지 다운 수\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        browser.implicitly_wait(1)\n",
    "\n",
    "    html0 = browser.page_source\n",
    "    html = BeautifulSoup(html0,'html.parser')\n",
    "\n",
    "    video_datas = html.find_all('ytd-video-renderer',{'class':'style-scope ytd-item-section-renderer'})\n",
    "    \n",
    "    print(len(video_datas), end = \" \")   #실행 시 지울 것\n",
    "    \n",
    "    video_url_list = []\n",
    "    for i in range(len(video_datas)):\n",
    "        url = yt_url + video_datas[i].find('a',{'id':'thumbnail'})['href']\n",
    "        video_url_list.append(url)\n",
    "\n",
    "    dataframe = pd.DataFrame({'name':[], 'youtube_url':[], 'views':[], \"nice\":[], \"reply\":[]})\n",
    "\n",
    "     \n",
    "    for i in range(len(video_datas)): \n",
    "        name = video_datas[i].find('a',{'id':'video-title'}).get_text()    \n",
    "        url = yt_url + video_datas[i].find('a',{'id':'thumbnail'})['href']\n",
    "    \n",
    "        cur_url = video_url_list[i]\n",
    "        browser.get(cur_url) \n",
    "        time.sleep(5)\n",
    "\n",
    "        body = browser.find_element_by_tag_name('body')\n",
    "\n",
    "        body.send_keys(Keys.PAGE_DOWN)\n",
    "        time.sleep(5)\n",
    "\n",
    "        html0 = browser.page_source\n",
    "        html = BeautifulSoup(html0,'html.parser')\n",
    "\n",
    "        try:\n",
    "            view_count = html.find('span',{'class':'view-count style-scope ytd-video-view-count-renderer'}).get_text().split()[1]\n",
    "            nice = html.find_all(\"yt-formatted-string\",{\"class\" : \"style-scope ytd-toggle-button-renderer style-text\"})[0]\n",
    "            nice_count = nice[\"aria-label\"].split()[-1]  #정확한 좋아요 수 반환\n",
    "\n",
    "            info = html.find('h2', {'class' : 'style-scope ytd-comments-header-renderer'})\n",
    "            reply_count = info.find_all('span', {'class' : 'style-scope yt-formatted-string'})[1].get_text()\n",
    "            \n",
    "            insert_data = pd.DataFrame({'name':[name], 'youtube_url':[url], 'views':[view_count], \"nice\":[nice_count], \"reply\":[reply_count]})\n",
    "            \n",
    "        except Exception as e:\n",
    "            continue \n",
    "                        \n",
    "        dataframe = dataframe.append(insert_data)\n",
    "        dataframe.to_excel(result, index = False)\n",
    "        \n",
    "        result.save()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43cf980b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uj200\\AppData\\Local\\Temp/ipykernel_33864/2080937167.py:13: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  browser = webdriver.Chrome(\"C:\\Program Files\\Google\\Chrome\\Application\\chromedriver_win32\\\\chromedriver.exe\")\n",
      "C:\\Users\\uj200\\AppData\\Local\\Temp/ipykernel_33864/2080937167.py:24: DeprecationWarning: find_element_by_tag_name is deprecated. Please use find_element(by=By.TAG_NAME, value=name) instead\n",
      "  body = browser.find_element_by_tag_name('body')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\uj200\\AppData\\Local\\Temp/ipykernel_33864/2080937167.py:53: DeprecationWarning: find_element_by_tag_name is deprecated. Please use find_element(by=By.TAG_NAME, value=name) instead\n",
      "  body = browser.find_element_by_tag_name('body')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 / 21 15 / 10 16 / 40 17 / 27 18 / 8 19 / 19 20 / 24 21 / 3 22 / 0 23 / 15 24 / 2 25 / 41 26 / 4 27 / 22 28 / 6 29 / 1 30 / 6 31 / 0 32 / 0 33 / 60 "
     ]
    }
   ],
   "source": [
    "#1차 main\n",
    "\n",
    "raw_data = xl.load_workbook('올리브영랭크100위화장품정보_2차.xlsx')\n",
    "raw_data = raw_data.active\n",
    "\n",
    "goods_name = raw_data[\"E\"][1::]\n",
    "brand_name = raw_data[\"F\"][1::]\n",
    "\n",
    "for i in range(14,40):\n",
    "    goods = f'{brand_name[i].value} {goods_name[i].value}'\n",
    "    crawling_youtube(goods)\n",
    "    print(i, end = \" / \")                             #실행 시 지울 것\n",
    "    \n",
    "browser.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
